<!--Todo: -->
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="FLute: Workshop on Federated Learning for Audio Understanding workshop at ICASSP 2025">
    <meta name="author" content="Soumyajit Chatterjee">
    <link rel="shortcut icon" href="https://www.ieee.org/" type="image/x-icon">
    <title>ICASSP 2025 FLute: Federated Learning for Audio Understanding </title>
    <meta name="theme-color" content="#157878" />
    <meta
      name="apple-mobile-web-app-status-bar-style"
      content="black-translucent"
    />
    <link rel="stylesheet" href="./assets/css/style.css?v=" />
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    
    <header class="page-header" role="banner">
     

      <h1 class="project-name">FLute: Federated Learning for Audio Understanding </h1>
      
      <h2 class="project-tagline">IEEE ICASSP 2025 Workshop</h2>
      <h2 class="project-tagline"><b>April, 2025</b>, Hyderabad, India</h2>



      <a href="./index.html" class="btn">Home</a>

      <a href="./cfp.html" class="btn">Call for Papers</a>

      <a href="./organizers.html" class="btn">Organizers</a>

      <a href="./speakers.html" class="btn">Speakers</a>

      <a href="./committee.html" class="btn">Program Committee</a>
<!-- 
      <a href="./schedule.html" class="btn">Program</a>

      <a href="./papers.html" class="btn">Accepted Papers</a>  -->
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="call-for-papers">Call for Papers</h1>

      <style>
        .foo {
          table-layout: fixed;
          width: 100%;
        }
      </style>

      <table class="foo">
        <tr>
          <td width="40%"><b>Submission deadline</b></td>
          <td width="60%">November 1, 2024 (AoE) </td>
        </tr>
        <tr>
          <td><b>Acceptance notification</b></td>
          <td>December 18, 2024</td>
        </tr>

        <tr>
          <td><b>Camera ready</b></td>
          <td>January 13, 2025</td>
        </tr>

        <tr>
          <td><b>Workshop</b></td>
          <td>April, 2025</td>
        </tr>
        

        <tr>
           <td><b>Submission website</b></td>
           <td>TBD</td>
        </tr>
        <!--    
        <tr>
          <td><b>Camera ready instructions</b></td>
        <td> Papers submitted for review should be 4-6 pages long (excluding references) in the double-column format. Please follow UbiComp's publication vendor <a href="https://www.ubicomp.org/ubicomp-iswc-2023/authors/formatting/">instructions</a> to prepare your manuscript.</td>
        </tr>
        -->   
      </table>


      <!-- <h2>Workshop Theme and Goals</h2>
      <p>
        We aim FLute to be an interdisciplinary forum beyond publications' solicitation that brings together academia and industry. Notably, we seek to bring together researchers and practitioners whose work lies across different IEEE Societies, as well as ML & AI, Social sciences, Philosophy, Law, and others. Workshop organizers are actively engaged in the aforementioned themes and will encourage their network of colleagues and students to participate in the workshop. In particular, the goal of this workshop is to collaboratively:
        <ul>
          <li>Evaluate the socio-technical progression and obstacles in Federated Learning (FL) within different applications in the audio domain.</li>
          <li>Chart ethical dimensions and potentials of FL, with emphasis on governance, training methods, and design choices.</li>
          <li>Conceptualize novel data gathering and training frameworks in FL to balance privacy with data integrity across various devices.</li>
          <li>Investigating advanced techniques to fortify model dependability and data protection in audio processing.</li>
          <li>Initiating dialogues on the future of "Audio FL" and jointly developing strategic research agendas.</li>
          <li>Building a global community to propel these initiatives, fostering collaborations via research and funding proposals.</li>
      </ul>

      </p> -->

        <h2>Call for Papers</h2>
        <p>
          The workshop aims to provide a platform for exchanging ideas on the future of federated learning surrounding audio applications. The main topics of interest include, <b>but are not limited to</b>:
        </p>

          <ul>
      <li>Applications of FL in the Audio Domain
          <ul>
              <li>Automatic Speech Recognition</li>
              <li>Audio, Sound and Music Processing</li>
              <li>Personalized Experiences</li>
              <li>Multi-Device, Multi-Modal, and Self-supervised FL</li>
              <li>Enhancing Healthcare</li>
          </ul>
      </li>
      <li>FL and LLMs for Advanced Audio Understanding
          <ul>
              <li>Prompt Tuning in FL Settings</li>
              <li>FL Frameworks for Foundation Models</li>
              <li>Exploiting LLM Embeddings for Audio Applications</li>
          </ul>
      </li>
      <li>Efficient FL for Audio Tasks
          <ul>
              <li>Addressing User and Device Heterogeneity</li>
              <li>Resource-Constrained FL</li>
              <li>Adaptive Aggregation Strategies</li>
              <li>Energy Efficiency</li>
          </ul>
      </li>
      <li>Robustness, Bias, and Interpretability in FL for Audio
          <ul>
              <li>Security and Privacy for Audio Tasks</li>
              <li>Bias and Interpretability</li>
              <li>Handling Cross-Domain Data</li>
              <li>Federated Unlearning</li>
          </ul>
      </li>
  </ul>


        <!-- <p>We encourage submissions from a wide range of disciplines, including machine learning, human-computer interaction, health data science, and related fields.</p> -->

        <h2>Submission tracks</h2>
        FLute 2025 will offer two primary submission tracks, both of which will be subject to a peer-review process. Works accepted in these tracks will be selected based on their technical quality and overall contribution to the event. The key distinctions between the tracks are outlined below:
        <h3>(A) Full Paper Track</h3>
        Submissions to the Full Paper Track should present well-developed, cohesive research with significant technical depth and clear, impactful relevance to federated learning for audio understanding. Accepted papers in this track will be published in the IEEE Xplore Digital Library.
        <h3>(B) Extended Abstract Track</h3>
        <p>
        The Extended Abstract Track is designed for submissions that foster insight and engagement at the event, whether through presenting innovative ideas, sparking meaningful discussions, sharing valuable resources, or facilitating new collaborations. This track is also particularly open to “non-traditional research artifacts,” such as papers introducing novel datasets, reporting insightful negative results, presenting preliminary findings that require prompt dissemination, conducting reproducibility studies, or offering opinion pieces and critiques.
        </p>
        <p>
          Extended abstracts can be up to 2 pages, including references. While these abstracts will not be published in the IEEE Xplore Digital Library, accepted authors will have the option (but are not required) to submit their work to arxiv.org and have it linked on the workshop’s website.        </p>

        
        <h2>Submission details</h2>
        The paper submission and reviewing process will be conducted through the ICASSP-2025 paper management system (Microsoft CMT) [Link available soon].  <a href="https://2025.ieeeicassp.org/author-kit-instructions/">Full papers should abide by the ICASSP-2025 paper style, format, and length.</a> 
        <p>In recognition of outstanding contributions, FLute 2025 will present a Best Paper Award to the top submission. This award will honor the work that demonstrates exceptional technical merit, innovation, and impact within the field of federated learning for audio understanding.
        </p>

        <!-- Any
        questions should be mailed to <a href="mailto:hcrlaaai@googlegroups.com">hcrlaaai@googlegroups.com</a>. -->
      </p>

      <!-- <h2>Attendance</h2>
      <p>We plan for an <strong>open, full-day workshop</strong> <strong>with 2 invited keynotes and accepted papers</strong> that include completed and ongoing original empirical works, case studies, reviews, as well as position papers (subject to number of submissions). All papers will be presented as talks, including Q&amp;A to allow researchers to engage in discussion with the workshop attendees.</p>
      <p>To further engage workshop participants, <em>workshopname</em> will include two interactive activities:</p>
      <ul>
          <li>a tiny tutorial, where participants will get a chance to play with state-of-the-art federated learning frameworks on a toy project;</li>
          <li>and an interactive panel on <em>"Challenges and opportunities of federated learning for Audio Understanding"</em> with keynote speakers and industry experts to further discuss reflections on their work with an open Q&amp;A session with the audience, moderated by one of the co-organizers.</li>
      </ul> -->


          <h2>Organizers</h2>
          <p> Lorena Qendro (Nokia Bell Labs / University of Cambridge) <br>
            Soumyajit Chatterjee (Nokia Bell Labs) <br>
            Aaqib Saeed (Eindhoven University of Technology) <br>
            Akhil Mathur (Meta) <br>
            Paolo Bellavista (University of Bologna) <br>
            Bj<span>&#246;</span>rn W. Schuller (Technische Universität München (TUM) / Imperial College London/audEERING) <br>
        </p>
    </main>
  </body>
</html>
